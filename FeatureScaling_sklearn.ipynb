{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674ecbfd",
   "metadata": {},
   "source": [
    "# FEATURE SCALING USING SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5bc32",
   "metadata": {},
   "source": [
    "Feature scaling is a technique of normalising large numerical values in small ranges to avoid inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7bf85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing  #for feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70210fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1,-1,2],\n",
    "           [2,0,0],\n",
    "          [0,1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffaa491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled=preprocessing.scale(X)  #this will do feature scaling in such a way that mean is zero and standard deviation becomes 1.\n",
    "x_scaled.mean(axis=0).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5613059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e3ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But a big drawback of feature scaling is we have to do scaling of train and well as test data,otherwise there will be inconsistent test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e616a1b",
   "metadata": {},
   "source": [
    "# The preprocessing module provides the StandardScaler utility class, which is a quick and easy way to perform the following operation on an array-like dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375d1780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=preprocessing.StandardScaler()  #standard scaling\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc195b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "200d8961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.22474487, -0.26726124]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take random input\n",
    "x_test=[[1,1,0]]\n",
    "scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e583c",
   "metadata": {},
   "source": [
    "# Scaling features to a range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ec584",
   "metadata": {},
   "source": [
    "An alternative standardization is scaling features to lie between a given minimum and maximum value, often between zero and one, or so that the maximum absolute value of each feature is scaled to unit size. This can be achieved using MinMaxScaler or MaxAbsScaler, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb076f",
   "metadata": {},
   "source": [
    "# min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "731ed970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "[ 1. 18.]\n",
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n",
      "[[1.5 0. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(data))\n",
    "print(scaler.data_max_)\n",
    "print(scaler.transform(data))\n",
    "print(scaler.transform([[2, 2]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b873a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6a0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
